{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb95dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Analysis \n",
    "class_distribution = Counter(helpfulness_ratings)\n",
    "total_data = len(helpfulness_ratings)\n",
    "\n",
    "\n",
    "for rating, count in class_distribution.items():\n",
    "    percentage = (count / total_data) * 100\n",
    "    print(f\"Class {rating}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(class_distribution.keys(), class_distribution.values())\n",
    "plt.xlabel('Helpfulness Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution in Full Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to ensure consistent ordering\n",
    "unique_labels = sorted(list(set(helpfulness_ratings)))\n",
    "unique_one_hot = np.diag(np.ones(len(unique_labels)))\n",
    "\n",
    "\n",
    "labels_train = [helpfulness_ratings[i] for i in train_ints]\n",
    "labels_test = [helpfulness_ratings[i] for i in test_ints]\n",
    "labels_dev = [helpfulness_ratings[i] for i in final_test_ints]\n",
    "\n",
    "# Make sure you're using the right label variables\n",
    "y_train = np.array([list(unique_one_hot[k]) for k in [unique_labels.index(x) for x in labels_train]]).T\n",
    "y_test = np.array([list(unique_one_hot[k]) for k in [unique_labels.index(x) for x in labels_test]]).T\n",
    "y_dev = np.array([list(unique_one_hot[k]) for k in [unique_labels.index(x) for x in labels_dev]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c36a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset example \n",
    "train_distribution = Counter(labels_train)\n",
    "print(train_distribution)\n",
    "test_distribution = Counter(labels_test)\n",
    "print(test_distribution)\n",
    "dev_distribution = Counter(labels_dev)\n",
    "print(dev_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_Softmax(x_train_data, y_train_data,x_test,y_test,lr =0.1,n_iters=1000,random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "\n",
    "    num_features = x_train_data.shape[1]\n",
    "    num_classes = y_train_data.shape[0]\n",
    "    num_samples = x_train_data.shape[0]\n",
    "\n",
    "    # Initialize weights with correct dimensions: (num_features, num_classes)\n",
    "    weights = np.random.rand(num_features, num_classes) # (8000,3)\n",
    "    bias = np.zeros(num_classes) # (3,)\n",
    "    \n",
    "    logistic_loss=[]\n",
    "\n",
    "\n",
    "\n",
    "    # # x and y now refer to the training data for intent classification\n",
    "    x_train_data = x_train_data  # Shape (num_samples, num_features) (21928, 8000)\n",
    "    y_train_targets = y_train_data.T # Shape (num_samples, num_classes) (3, 21928)\n",
    "    # print(x_train_data.shape)\n",
    "    # print(y_train_targets.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_iters):\n",
    "\n",
    "        # z = x.dot(weights) expects x to be (num_samples, num_features) and weights to be (num_features, num_classes)\n",
    "        z= x_train_data.dot(weights) + bias\n",
    "        \n",
    "        # Softmax \n",
    "        exp_z = np.exp(z)\n",
    "        q = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        # exp_z = np.exp(z)\n",
    "        # q = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        \n",
    "        \n",
    "        # Calculate loss using y_train_targets\n",
    "        eps = 1e-12\n",
    "        # Softmax cross entropy loss with clipping to prevent log(0)\n",
    "        loss = (-np.sum(y_train_targets*np.log2(np.clip(q, eps, 1.0)))) / num_samples # avoid log(0)\n",
    "    \n",
    "        logistic_loss.append(loss)\n",
    "\n",
    "        # dw = x.T.dot((q-y)) expects x.T to be (num_features, num_samples) and (q-y) to be (num_samples, num_classes)\n",
    "        # Here x_train_data.T is (num_features, num_samples)\n",
    "        db = np.sum((q-y_train_targets), axis=0)/num_samples\n",
    "        dw=x_train_data.T.dot((q-y_train_targets))/num_samples\n",
    "        weights=(weights - (dw*lr))\n",
    "        bias=(bias - (db*lr))\n",
    "    result = LogReg_Softmax_Test(weights,bias,x_test,y_test)\n",
    "    return weights,bias,result,logistic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ae73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg_Softmax_Test(weights,bias,x_dataset,y_dataset):\n",
    "    # Forward pass on test data\n",
    "    z_test = x_dataset.dot(weights) + bias\n",
    "    # Perform theSoftmax\n",
    "    exp_z_test = np.exp(z_test)\n",
    "    q_test = exp_z_test / np.sum(exp_z_test, axis=1, keepdims=True)\n",
    "    # Get predictions, basically get the class with highest probability\n",
    "    y_pred_test = np.argmax(q_test, axis=1)  # Shape: (7310,)\n",
    "\n",
    "    # Get true labels\n",
    "    y_test_targets = y_dataset.T  \n",
    "    y_true_test = np.argmax(y_test_targets, axis=1)  # Shape: (7310,)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy_test = np.mean(y_pred_test == y_true_test)\n",
    "    print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "    TP = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    for j in range(3):\n",
    "        TP.append(np.sum(np.array([int(s == j and y_true_test[i] == j) for i,s in enumerate(y_pred_test)])))\n",
    "        FP.append(np.sum(np.array([int(s == j and y_true_test[i] != j) for i,s in enumerate(y_pred_test)])))\n",
    "        FN.append(np.sum(np.array([int(s != j and y_true_test[i] == j) for i,s in enumerate(y_pred_test)])))\n",
    "    \n",
    "    precision = np.array(TP)/(np.array(TP)+np.array(FP))\n",
    "    recall = np.array(TP)/(np.array(TP)+np.array(FN))\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LogReg_models_softmax = {}\n",
    "for lr in learning_rates:\n",
    "    print(\"Learning rate: \",lr)\n",
    "    weights,bias,result,loss = LogisticRegression_Softmax(M_train,y_train,M_test,y_test,lr=lr) \n",
    "    print(\"-----\")\n",
    "    LogReg_models_softmax[lr] = (weights,bias,result,loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d89162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_softmax(x_train,y_train,x_test,y_test,lr=0.1,hidden_size=16,n_iters=1000,):\n",
    "\n",
    "    # Add more layers for hte multilayer perceptron\n",
    "    num_features= x_train.shape[1]\n",
    "    num_classes = 3\n",
    "\n",
    "    helpfulness_labels = y_train # 3,2198\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Intitiliasation method based on Xavier's proposed method \n",
    "    # https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf#page=4.98\n",
    "    limit_1 = np.sqrt(6 / (num_features ))\n",
    "    weights_0_1 = np.random.uniform(-limit_1, limit_1, (num_features, hidden_size))\n",
    "    limit_2 = np.sqrt(6 / (hidden_size ))\n",
    "    weights_1_2 = np.random.uniform(-limit_2, limit_2, (hidden_size,num_classes))\n",
    "    y_train_target = y_train.T\n",
    "\n",
    "    loss_history = []\n",
    "    \n",
    "    num_samples = x_train.shape[0] # Number of training samples\n",
    "\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        layer_2_error = 0\n",
    "        layer_0 = x_train\n",
    "\n",
    "        ## Add forward pass\n",
    "        layer_1 = np.maximum(np.dot(layer_0,weights_0_1),0)\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "    \n",
    "\n",
    "\n",
    "        # Then apply sigmoid\n",
    "        # layer_2_s = 1/(1+np.exp(-layer_2))\n",
    "        exp_z = np.exp(layer_2)\n",
    "        layer_2_s = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        q = layer_2_s\n",
    "\n",
    "\n",
    "    \n",
    "        eps = 1e-8\n",
    "         # Softmax cross entropy loss with clipping to prevent log(0)\n",
    "        loss = -(np.sum(y_train.T*np.log2(np.clip(q, eps, 1.0))))/num_samples  # avoid log(0)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "\n",
    "        ## Add backward pass and update weights\n",
    "        layer_2_diff = (layer_2_s - y_train_target)\n",
    "\n",
    "        z1 = np.dot(layer_0, weights_0_1)\n",
    "        relu_grad = (z1 > 0).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "        hidden_delta = np.dot(layer_2_diff, weights_1_2.T) * relu_grad\n",
    "\n",
    "        # Normalize weight updates by N\n",
    "        weights_1_2 -= lr   * (np.dot(layer_1.T, layer_2_diff) /num_samples)\n",
    "        weights_0_1 -= lr * (np.dot(layer_0.T, hidden_delta) / num_samples)\n",
    "    result = MLP_softmax_test(weights_0_1,weights_1_2,x_test,y_test)    \n",
    "    return weights_0_1, weights_1_2,result, loss_history\n",
    "\n",
    "def MLP_softmax_test(weights_0_1, weights_1_2, x_dataset,y_dataset):\n",
    "    layer_0_test = x_dataset    \n",
    "    layer_1_test = np.maximum(np.dot(layer_0_test, weights_0_1), 0)  # ReLU activation\n",
    "    layer_2_test = np.dot(layer_1_test, weights_1_2)\n",
    "\n",
    "    # Apply softmax\n",
    "    exp_z_test = np.exp(layer_2_test)\n",
    "    layer_2_s_test = exp_z_test / np.sum(exp_z_test, axis=1, keepdims=True)\n",
    "\n",
    "    # Get predictions (class with highest probability)\n",
    "    y_pred_test = np.argmax(layer_2_s_test, axis=1)\n",
    "\n",
    "    # Get true labels\n",
    "    y_true_test = np.argmax(y_dataset.T, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy_test = np.mean(y_pred_test == y_true_test)\n",
    "    print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "    TP = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    for j in range(3):\n",
    "        TP.append(np.sum(np.array([int(s == j and y_true_test[i] == j) for i,s in enumerate(y_pred_test)])))\n",
    "        FP.append(np.sum(np.array([int(s == j and y_true_test[i] != j) for i,s in enumerate(y_pred_test)])))\n",
    "        FN.append(np.sum(np.array([int(s != j and y_true_test[i] == j) for i,s in enumerate(y_pred_test)])))\n",
    "    \n",
    "    precision = np.array(TP)/(np.array(TP)+np.array(FP))\n",
    "    recall = np.array(TP)/(np.array(TP)+np.array(FN))\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b058b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_models_softmax = {}\n",
    "for lr in learning_rates:\n",
    "    print(\"Learning rate: \",lr)\n",
    "    weights,bias,result,loss = MLP_softmax(M_train,y_train,M_test,y_test,lr=lr) \n",
    "    print(\"-----\")\n",
    "    MLP_models_softmax[lr] = (weights,bias,result,loss)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
